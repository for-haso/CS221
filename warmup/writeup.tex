\documentclass[12pt]{article}
\usepackage{fullpage,enumitem,amsmath,amssymb,graphicx,comment}

\begin{document}

\begin{center}
{\Large CS221 Fall 2013 Homework 1: Warmup}

\begin{tabular}{rl}
SUNet ID: & nisham \\
Name: & Nisha Masharani \\
Collaborators: & sryoung, alesan92
\end{tabular}
\end{center}

By turning in this assignment, I agree by the Stanford honor code and declare
that all of this is my own work.

\section*{Problem 1}

\begin{enumerate}[label=(\alph*)]

  \item To minimize, solve $f'(x) = 0$.
  \begin{eqnarray*}
  f(x) &=& \frac{1}{2}\displaystyle\sum\limits_{i=1}^n w_i (x-b_i)^2\\
  \end{eqnarray*}
  Find $f'(x)$.
  \begin{eqnarray*}
  f'(x) &=& \frac{d}{dx}\biggl[\frac{1}{2}\displaystyle\sum\limits_{i=1}^n w_i (x-b_i)^2\biggr]\\
  &=& \frac{1}{2}\displaystyle\sum\limits_{i=1}^n 2w_i (x-b_i)\\
  &=& \displaystyle\sum\limits_{i=1}^n w_i (x-b_i)\\
  \end{eqnarray*}
  Set $f'(x) = 0$ and solve for x.
  \begin{eqnarray*}
  f'(x) &=& 0\\
  \displaystyle\sum\limits_{i=1}^n w_i (x-b_i) &=& 0\\
  \displaystyle\sum\limits_{i=1}^n w_i x - \displaystyle\sum\limits_{i=1}^n w_i b_i &=& 0\\
  x \displaystyle\sum\limits_{i=1}^n w_i &=& \displaystyle\sum\limits_{i=1}^n w_i b_i\\
  x &=& \frac{\sum_{i=1}^n w_i b_i}{\sum_{i=1}^n w_i}
  \end{eqnarray*}

  \item First, let us rewrite $f(x)$ and $g(x)$ to expand out the max functions. 
  \begin{eqnarray*}
  f(x) &=& \max_{a \in \lbrace1, -1\rbrace} \displaystyle\sum\limits_{j=1}^d ax_j\\
  &=& max \biggl\lbrace \displaystyle\sum\limits_{j=1}^d x_j , \displaystyle\sum\limits_{j=1}^d -x_j \biggr\rbrace\\
  g(x) &=& \displaystyle\sum\limits_{j=1}^d \max_{a \in \{1,-1\}} a x_j\\
  &=& \displaystyle\sum\limits_{j=1}^d \max \biggl\lbrace x_j , -x_j \biggr\rbrace\\
  \end{eqnarray*}
  If all $x_j \ge 0$ or all $x_j \le 0$, then $f(x) = g(x)$ because $f(x)$ will take the sum of all $x_j$ and then take the absolute value to find the max, while $g(x)$ will take the absolute value of all $x_j$ and then sum them, resulting in the same answer if the signs of all $x_j$ are the same. If the signs of all $x_j$ are not the same, then $g(x) > f(x)$ because at least one element in the sum of $f(x)$ will be different from the others, so adding that number to the sum will decrease the magnitude of the sum. Thus, $g(x) \ge f(x)$.

  \item
  $X_i = \left \{
     \begin{array}{ll}
       0 & \mbox{if the ith roll is 1, 2, or 3}\\
       4 & \mbox{if the ith roll is 4}\\
       5 & \mbox{if the ith roll is 5}\\
       6 & \mbox{if the ith roll is 6}\\
     \end{array}
   \right.
   $
  \begin{eqnarray*}
  E\biggl[\displaystyle\sum\limits_{i=1}^n X_i\biggr] &=& \displaystyle\sum\limits_{i=1}^n E\biggl[X_i\biggr]\\
  E\biggl[X_i\biggr] &=& \frac{3}{6} (0) + \frac{1}{6} (4) + \frac{1}{6} (5) + \frac{1}{6} (6) \\
  &=& \frac{15}{6}\\
  E\biggl[\displaystyle\sum\limits_{i=1}^n X_i\biggr] &=& \displaystyle\sum\limits_{i=1}^n E\biggl[X_i\biggr]\\
  &=& \frac{15}{6} n
  \end{eqnarray*}
  The dice rolls do not have to be independent for the expectation of the sum to equal the sum of the expectation.

  \item
  $L(p) = p^3(1-p)^2$\\
  If we maximize $\log(L(p))$, that is the same as maximizing $L(p)$, because the log function is one to one and increasing, so the $p$ value at the maxima of both functions are the same.
  \begin{eqnarray*}
  \log(L(p)) &=& \log(p^3(1-p)^2)\\
  &=& \log(p^3) + \log((1-p)^2)\\
  &=& 3\log(p) + 2\log(1-p)\\
  \end{eqnarray*}
  To find the minimum, take the derivative and set it equal to zero, then solve for p.
  \begin{eqnarray*}
  \frac{d}{dp}\biggl[\log(L(p))\biggr] &=& 3\biggl(\frac{1}{p}\biggr) + -2\biggl(\frac{1}{1-p}\biggr)\\
  &=& \frac{3(1-p) - 2(p)}{p(1-p)}\\
  &=& 0\\
  \frac{3(1-p) - 2(p)}{p(1-p)} &=& 0\\
  3(1-p) - 2(p) &=& 0\\
  3 - 3p &=& 2p\\
  p &=& \frac{3}{5}\\
  \end{eqnarray*}

\end{enumerate}

\section*{Problem 2}

\begin{enumerate}[label=(\alph*)]
  \item For each word in the sentence, there are 4 classifications. There are n words in the sentence. Thus, there are $4^n$ possible different tag sequences.
  
  \item For each rectangle, we want to define dimensions and a position. We can do this in several ways, but the easiest way to do so is to use the grid lines in the pixel grid. We need two horizontal lines and two vertical lines to define a grid. In an $n x n$ grid, there are $n + 1$ vertical edges and $n + 1$ horizontal edges. Since we're choosing two of each, the number of possibilities for each rectangle is:
  \begin{eqnarray*}
  \binom{n+1}{2}\binom{n+1}{2} &=& \frac{(n+1)!(n+1)!}{(n-1)!2!(n-1)!2!}\\
  &=& \frac{(n+1)n(n+1)n}{4}\\
  \end{eqnarray*}
  Since we're doing this for 3 rectangles (2 eyes and a mouth), the total number of arrangements is $(\frac{(n+1)n(n+1)n}{4})^3$
  Thus, the asymptotic complexity is $O(n^{12})$

  \item $f(n) = \min_{1 \le i < n} [c(i, n) + f(i)]$\\
  For this problem, we use dynamic programming to store all calculated values of f(i). That way, if we calculate f(i), we do not have to re-calculate f(i), which makes our program significantly more efficient.\\
  \begin{eqnarray*}
  f(j) &=& \min_{1 \le i < j} [c(i, j) + f(i)]\\
  &=& \min\biggl(c(1, j) + f(1), c(2, j) + f(2), ..., c(j-1, j) + f(j-1)\biggr)\\
  \end{eqnarray*}
  Because of the order of the minimum function, $f(1)$ is calculated first, and then is cached. Therefore, when $f(2)$ is calculated, it can just refer to the cached version of $f(1)$. Similarly, when $f(3)$ is calculated, it can refer to the cached versions of $f(1)$ and $f(2)$. Therefore, when $f(j)$ is calculated, it can simply do a constant time lookup for all values of $f(i)$ where $1 \le i < j$. Calling $c(i, j)$ is given to be constant time for all $1 \le i < j$, so calculating $c(i, j)$ for all $1 \le i < j$ takes $O(j-1)$ time because we're doing an $O(1)$ operation $j-1$ times. \\
   \\
  Therefore, the run time for $f(j)$ becomes the time it takes to calculate $c(i, j)$ for all $1 \le i < j$, which is $O(j-1)$, plus the time it takes to lookup all cached versions of $f(i)$ for all $1 \le i < j$, which is also $O(j-1)$. However, we cannot simply say $O(f(j)) = O(j-1)$, because the first time each $f(i)$ is called for all $1 \le i < j$, the value of $f(i)$ is not yet cached. \\
   \\
  Therefore, we must recursively do a calculation to find the value of $f(i)$ based on a constant time lookup of all previously cached values up to that point and constant time $c(i, j)$ calls, so $O(f(i)) = O(i)$, because all values we're using to calculate $O(i)$ are cached.\\
   \\
  Thus, $O(f(j)) = O(f(1) + ... + f(j-1))$, which becomes $O(1 + 2 + ... + (j-2) + (j-1))$. Therefore, we can write the total run time to be: 

  \begin{eqnarray*}
  O(f(n)) &=& O\biggl(\displaystyle\sum\limits_{i=1}^{n-1} n-i\biggr)\\
  &=& O(n^2)\\
  \end{eqnarray*}
\end{enumerate}

\end{document}
