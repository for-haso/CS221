\documentclass[12pt]{article}
\usepackage{fullpage,enumitem,amsmath,amssymb,graphicx}

\begin{document}

\begin{center}
{\Large CS221 Fall 2013 Homework: Spam}

\begin{tabular}{rl}
SUNet ID: & nisham \\
Name: & Nisha Masharani \\
Collaborators: & sryoung, alesan92
\end{tabular}
\end{center}

By turning in this assignment, I agree by the Stanford honor code and declare
that all of this is my own work.

\section*{Problem 1.1}

\begin{enumerate}[label=(\alph*)]
  \item See code for part A.

  \item 
	  \begin{tabular}{ l | p{3cm} | p{3cm} | p{3cm} }
	    \hline
	     & 1 & 2 & 3\\ \hline
	    10000 & train: 0.114308, dev: 0.105919 & train: 0.167631, dev: 0.165109 & train: 0.215168, dev: 0.204361 \\ \hline
	    20000 & train: 0.168100, dev: 0.163863 & train: 0.114464, dev: 0.118380 & train: 0.106646, dev: 0.106542 \\ \hline
	    30000 & train: 0.482252, dev: 0.489720 & train: 0.470993, dev: 0.477882 & train: 0.457076, dev: 0.464174 \\ \hline
	  \end{tabular}
\end{enumerate}

\section*{Problem 1.2}

\begin{enumerate}[label=(\alph*)]
  \item See code for part A.
  \item See code for part B.
  \item Let $w$ be a vector containing a score of $1.0$ for the first $k$ words in the blacklist, and a score of $0.0$ for all words not in the blacklist. Then $w \cdot \phi(x)$ ends up being equal to the count of all blacklisted words in the email. For example, if the blacklist contains the words "hello" and "goodbye", then $w$ = {"hello": 1.0, "goodbye": 1.0}. If I have an email that reads "hello my name is joe.", $\phi(x)$ = {"hello": 1.0, "my": 1.0, "name": 1.0, "is": 1.0, "joe": 1.0}. $w \cdot \phi(x)$ will then be 1.0, which is consistent with the score from the rule-based classifier. We can write the mathematical output of the classifier as follows:

  $\hat y = \left\{ \begin{matrix} 
	1 ~\textrm{if}~ w \cdot \phi(x) - n \ge 0\\
	-1 ~\textrm{if}~ w \cdot \phi(x) - n< 0
	\end{matrix}\right..$
\end{enumerate}

\section*{Problem 1.3}

\begin{enumerate}[label=(\alph*)]
  \item See code for part A.
  \item See code for part B.

  \item "We have recently had a security breach of our servers. Please go to this link and enter your username and password so we can ensure that your account has not been compromised."\\
  Each word is more or less fine, but the bigrams "please go" "this link" "enter your" "your username" "username and" "and password" are all pretty sketchy. Something like this may be classified as a server admin email (not spam) by a classifier using a unigram feature vector, but as spam by a classifier using a bigram feature vector.
  \item 
  \begin{tabular}{ l | p{3cm} | p{3cm} }
	    \hline
	    Num examples & trainErrorRate & devErrorRate\\ \hline
	    500 & 
		0.079281 & 0.087227 \\ \hline
		1000 & 
		0.049257 & 0.064798 \\ \hline
		1500 & 
		0.041126 & 0.057944 \\ \hline
		2000 & 
		0.025958 & 0.041121 \\ \hline
		2500 & 
		0.021579 & 0.040498 \\ \hline
		3000 & 
		0.019234 & 0.038006 \\ \hline
		3500 & 
		0.016888 & 0.038629 \\ \hline
		4000 & 
		0.012979 & 0.037383 \\ \hline
		4500 & 
		0.010790 & 0.031153 \\ \hline
		5000 & 
		0.009226 & 0.039252 \\ \hline
	  \end{tabular}
\end{enumerate}

\section*{Problem 2}

\begin{enumerate}[label=(\alph*)]
  \item 
  Unigram:\\
  trainErrorRate: 0.032847\\
devErrorRate: 0.168539\\
  Bigram:\\
  trainErrorRate: 0.000000\\
  devErrorRate: 0.162921\\
  \item
  \begin{tabular}{ l | p{3cm} | p{3cm} }
    \hline
    Num iters & trainErrorRate & devErrorRate\\ \hline
1 & 
0.291971 & 0.365169 \\ \hline
2 & 
0.453771 & 0.483146 \\ \hline
3 & 
0.142336 & 0.292135 \\ \hline
4 & 
0.502433 & 0.511236 \\ \hline
5 & 
0.049878 & 0.162921 \\ \hline
6 & 
0.479319 & 0.505618 \\ \hline
7 & 
0.150852 & 0.370787 \\ \hline
8 & 
0.019465 & 0.162921 \\ \hline
9 & 
0.029197 & 0.157303 \\ \hline
10 & 
0.014599 & 0.146067 \\ \hline
11 & 
0.104623 & 0.308989 \\ \hline
12 & 
0.008516 & 0.168539 \\ \hline
13 & 
0.038929 & 0.252809 \\ \hline
14 & 
0.017032 & 0.196629 \\ \hline
15 & 
0.008516 & 0.179775 \\ \hline
16 & 
0.004866 & 0.179775 \\ \hline
17 & 
0.000000 & 0.162921 \\ \hline
18 & 
0.000000 & 0.162921 \\ \hline
19 & 
0.000000 & 0.162921 \\ \hline
20 & 
0.000000 & 0.162921 \\ \hline
  \end{tabular}

    Dev error rate does more or less increase monotonically with training error rate. This makes sense because, as the training error rate decreases, the model ends up fitting the training data. If the training data is similar to the dev data, and the model has not been over-fitted to the training data, the dev error rate should decrease as well. If the model has been over-fitted to the training data (which we do not see here), we would see the dev error rate start to increase as the training error rate gets really small. 

\end{enumerate}

\section*{Problem 3}

\begin{enumerate}[label=(\alph*)]
  \item See code for part A.

  \item 
	Unigram:\\
	trainErrorRate: 0.003909\\
devErrorRate: 0.120249\\
  Bigram:\\
  trainErrorRate: 0.000000\\
devErrorRate: 0.100935\\
\item To find the gradients with respect to $w_1, w_2, ..., w_k$, we want to take the gradient of the loss function with respect to both $w_t$ and $w_y$. 

\begin{eqnarray*}
\frac{\partial}{\partial w_t} \biggl[\mathbb{I}(y \neq t) + w_{t} \cdot \phi(x) - w_{y} \cdot \phi(x) \biggr] &=& \phi(x)\\
\frac{\partial}{\partial w_y} \biggl[\mathbb{I}(y \neq t) + w_{t} \cdot \phi(x) - w_{y} \cdot \phi(x) \biggr] &=& -\phi(x)\\
\end{eqnarray*}

For all $t \ne y$, we get that the subgradient is just $\phi(x)$, because we don't have to take the partial derivative w.r.t. $w_y$. However, when $t = y$, the subgradient becomes $\frac{\partial}{\partial w_t} + \frac{\partial}{\partial w_y}$, meaning the subgradient is $0$.

\end{enumerate}

\end{document}
